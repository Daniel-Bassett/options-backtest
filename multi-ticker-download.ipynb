{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d8f3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import polygon\n",
    "import polygon\n",
    "from polygon import RESTClient\n",
    "\n",
    "# import visualization packages\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot\n",
    "import plotly.express as px\n",
    "\n",
    "# import yahoo finance api to get past earnings dates\n",
    "import yfinance as yf\n",
    "\n",
    "# import pandas and datetime\n",
    "import statistics\n",
    "import pandas_market_calendars as mcal\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "# import time datetime\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# for exporting data\n",
    "import pickle\n",
    "\n",
    "# import API_KEY from config\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa16d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter desire tickers\n",
    "tickers = ['T']\n",
    "client = RESTClient(API_KEY)\n",
    "\n",
    "def get_net_pnl(call_df, put_df, start_date):\n",
    "#     bug finder\n",
    "#     print((call_df['option ticker'].iloc[0], put_df['option ticker'].iloc[0]))\n",
    "    call = client.get_aggs(\n",
    "        ticker = call_df['option ticker'].iloc[0],\n",
    "        limit=10000,\n",
    "        multiplier = 1, \n",
    "        timespan = 'day', \n",
    "        from_ = start_date, \n",
    "        to = earnings_date,\n",
    "        adjusted=False\n",
    "    )\n",
    "    put = client.get_aggs(\n",
    "        ticker = put_df['option ticker'].iloc[0],\n",
    "        limit=10000,\n",
    "        multiplier = 1, \n",
    "        timespan = 'day', \n",
    "        from_ = start_date, \n",
    "        to = earnings_date,\n",
    "        adjusted=False\n",
    "    )\n",
    "    call = pd.DataFrame(call)\n",
    "    call['date'] = pd.to_datetime(call['timestamp'] * 1000000).dt.normalize()\n",
    "\n",
    "\n",
    "    put = pd.DataFrame(put)\n",
    "    put['date'] = pd.to_datetime(put['timestamp'] * 1000000).dt.normalize()\n",
    "    \n",
    "    valid_dates = pd.to_datetime(get_valid_dates(start_date, earnings_date))\n",
    "    valid_dates = pd.DataFrame(valid_dates, columns=['date'])\n",
    "    \n",
    "    call = pd.merge(valid_dates, call, how='outer')\n",
    "    put = pd.merge(valid_dates, put, how='outer')\n",
    "    \n",
    "#     bug finder\n",
    "#     print((len(call), len(put)))\n",
    "#     print((start_date, earnings_date))\n",
    "#     print('--------------------------')\n",
    "    \n",
    "    # create dataframe of net close of straddle\n",
    "    net_df = pd.DataFrame()\n",
    "    net_df['close'] = call['close'] + put['close']\n",
    "    \n",
    "    # creates column name based on how many days before earnings the straddle was placed\n",
    "    col_name = f'{len(net_df)} days'\n",
    "    net_df[col_name] = ((net_df['close'] - net_df['close'].iloc[0]) / net_df['close'].iloc[0]) * 100\n",
    "    \n",
    "    # just copy the date column from call and use it for the net_df\n",
    "    net_df['date'] = call['date']\n",
    "    \n",
    "    # create a 'days remaining' before earnings column\n",
    "#     net_df['days remaining'] = sorted(range(len(net_df)), reverse=True)\n",
    "    \n",
    "    net_df.drop('close', axis=1, inplace=True)\n",
    "    return net_df\n",
    "\n",
    "def get_contracts(search_date, earnings_date):\n",
    "    start_date = (pd.to_datetime(earnings_date) - dt.timedelta(days=40)).date().strftime('%Y-%m-%d')\n",
    "\n",
    "    contracts_df = []\n",
    "    for c in client.list_options_contracts(ticker, limit=1000, as_of=start_date):\n",
    "        contracts_df.append({\n",
    "            'expiration date': c.expiration_date,\n",
    "            'type': c.contract_type,\n",
    "            'strike price': c.strike_price,\n",
    "            'option ticker': c.ticker\n",
    "        })\n",
    "    contracts_df = pd.DataFrame(contracts_df)\n",
    "    contracts_df['expiration date'] = pd.to_datetime(contracts_df['expiration date'])\n",
    "    return contracts_df\n",
    "\n",
    "def get_valid_dates(search_date, earnings_date):\n",
    "    nyse = mcal.get_calendar('NYSE')\n",
    "    valid_dates = nyse.valid_days(start_date=search_date, end_date=earnings_date)\n",
    "    valid_dates = [date.date().strftime('%Y-%m-%d') for date in valid_dates]\n",
    "    valid_dates = valid_dates[-22:]\n",
    "    return valid_dates\n",
    "\n",
    "def get_underlying(start_date, earnings_date, ticker):\n",
    "    # get the price history of the underlying ticker from the start_date to earnings_date \n",
    "    underlying = client.get_aggs(ticker=ticker, from_=start_date, to=earnings_date, multiplier=1, timespan='day', adjusted=False)\n",
    "    underlying = pd.DataFrame(underlying)\n",
    "    underlying['date'] = pd.to_datetime(underlying['timestamp'] * 1000000).dt.date\n",
    "    return underlying\n",
    "\n",
    "def process_df(df_list, avg_days):\n",
    "    aggregate_df = pd.concat(df_list)\n",
    "    aggregate_df.reset_index(inplace=True)\n",
    "    aggregate_df['index'] = aggregate_df['index'].str.strip(' days').astype('int')\n",
    "    aggregate_df_median = aggregate_df.groupby('index').median().sort_index(ascending=False)\n",
    "    aggregate_df_median.index = aggregate_df_median.index.astype('str')\n",
    "    aggregate_df_mean = aggregate_df.groupby('index').mean().sort_index(ascending=False)\n",
    "    aggregate_df_mean.index = aggregate_df_mean.index.astype('str')\n",
    "    aggregate_df_min = aggregate_df.groupby('index').min().sort_index(ascending=False)\n",
    "    aggregate_df_min.index = aggregate_df_min.index.astype('str')\n",
    "    aggregate_df_max = aggregate_df.groupby('index').max().sort_index(ascending=False)\n",
    "    aggregate_df_max.index = aggregate_df_max.index.astype('str')\n",
    "    aggregate_df.index = aggregate_df.index.astype('str')\n",
    "    return {'mean': aggregate_df_mean, 'median':aggregate_df_median, 'max': aggregate_df_max, 'min': aggregate_df_min, 'avg_days': avg_days}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ccdfb44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was a \"no results\" error! ticker: T, earnings date: 2022-10-20\n",
      "There was a \"no results\" error! ticker: T, earnings date: 2022-10-20\n",
      "T 2022-10-20 complete\n",
      "There was a \"no results\" error! ticker: T, earnings date: 2022-07-21\n",
      "There was a \"no results\" error! ticker: T, earnings date: 2022-07-21\n",
      "There was a \"no results\" error! ticker: T, earnings date: 2022-07-21\n",
      "There was a \"no results\" error! ticker: T, earnings date: 2022-04-21\n",
      "There was a \"no results\" error! ticker: T, earnings date: 2022-04-21\n",
      "There was a \"no results\" error! ticker: T, earnings date: 2022-04-21\n",
      "T 2022-01-26 complete\n",
      "T 2022-01-26 complete\n",
      "T 2022-01-26 complete\n",
      "T 2021-10-21 complete\n",
      "T 2021-10-21 complete\n",
      "T 2021-10-21 complete\n",
      "T 2021-07-22 complete\n",
      "T 2021-07-22 complete\n",
      "T 2021-07-22 complete\n",
      "--------T is complete----------\n"
     ]
    }
   ],
   "source": [
    "for ticker in tickers:\n",
    "    errors = []\n",
    "    stock = yf.Ticker(ticker)\n",
    "    earnings_dates = stock.get_earnings_dates(limit=11).dropna(axis=0).reset_index()\n",
    "\n",
    "    # if earnings is after market close, set earnings date to next day\n",
    "    earnings_dates.loc[earnings_dates['Earnings Date'].dt.hour > 6, 'Earnings Date'] =  earnings_dates['Earnings Date'] + dt.timedelta(days=1)\n",
    "    earnings_dates = earnings_dates['Earnings Date'].dt.date\n",
    "    dates_export = [a_date.strftime('%Y-%m-%d') for a_date in earnings_dates]\n",
    "    with open(f'data/{ticker}-earnings-dates.pickle', 'wb') as f:\n",
    "        pickle.dump(dates_export, f)\n",
    "\n",
    "    # define df lists that will be turned into dfs of aggregate functions\n",
    "    near_aggregate_df = []\n",
    "    med_aggregate_df = []\n",
    "    far_aggregate_df = []\n",
    "\n",
    "    for earnings_date in earnings_dates:\n",
    "\n",
    "        search_date = (pd.to_datetime(earnings_date) - dt.timedelta(days=40)).date().strftime('%Y-%m-%d')\n",
    "\n",
    "        valid_dates = get_valid_dates(search_date, earnings_date)\n",
    "\n",
    "        contracts_df = get_contracts(search_date, earnings_date)\n",
    "\n",
    "        start_date = valid_dates[-22]\n",
    "\n",
    "        underlying = get_underlying(start_date, earnings_date, ticker)\n",
    "\n",
    "        near_avg_days_after_earnings = []\n",
    "        med_avg_days_after_earnings = []\n",
    "        far_avg_days_after_earnings = []\n",
    "\n",
    "        valid_expirations_mask = contracts_df['expiration date'].dt.date >= earnings_date\n",
    "        i = 0\n",
    "        for expiration_date in contracts_df[valid_expirations_mask]['expiration date'].unique()[0:3]:\n",
    "            try:\n",
    "                expiration_mask = contracts_df['expiration date'] == expiration_date\n",
    "                call_mask = contracts_df['type'] == 'call'\n",
    "                put_mask = contracts_df['type'] == 'put'\n",
    "\n",
    "                list_of_df = []\n",
    "                for date in valid_dates:    \n",
    "                    date_mask = underlying['date'] == pd.to_datetime(date)\n",
    "                    stock_price = underlying[date_mask]['close']\n",
    "                    contracts_df.iloc[abs(contracts_df[expiration_mask]['strike price'] - stock_price.iloc[0]).sort_values().head(2).index]\n",
    "\n",
    "                    call = contracts_df.iloc[abs(contracts_df[expiration_mask & call_mask]['strike price'] - stock_price.iloc[0]).sort_values().head(1).index]\n",
    "                    put = contracts_df.iloc[abs(contracts_df[expiration_mask & put_mask]['strike price'] - stock_price.iloc[0]).sort_values().head(1).index]\n",
    "\n",
    "                    list_of_df.append(get_net_pnl(call, put, date))\n",
    "                    time.sleep(0.10)\n",
    "\n",
    "                all_df = pd.DataFrame(columns=['date'])\n",
    "                for dframe in list_of_df:\n",
    "                    all_df = pd.merge(all_df, dframe, how='outer', on='date')\n",
    "    #             all_df.dropna(axis=0, how='all', inplace=True)\n",
    "\n",
    "                days_after_earnings = (pd.to_datetime(expiration_date).date() - pd.to_datetime(all_df['date'].iloc[-1]).date()).days\n",
    "\n",
    "\n",
    "                # create date_df for individual heatmaps\n",
    "                date_df = all_df\n",
    "                date_df.set_index('date', inplace=True)\n",
    "                date_df.sort_index(inplace=True)\n",
    "                date_df = date_df.transpose()\n",
    "    #             date_df.dropna(how='all', axis=1, inplace=True) # drop columns whose data is completely missing\n",
    "                date_df.sort_index()\n",
    "\n",
    "                # create the dates value DF for the hovertemplate\n",
    "                for column in date_df:\n",
    "                    date_df[column] = date_df[column].name\n",
    "                new_column_names = [num for num in range(21, 0, -1)]\n",
    "                new_column_names.append('After Earnings')\n",
    "                date_df.columns = new_column_names\n",
    "                date_df = date_df.astype('str')\n",
    "\n",
    "\n",
    "                # use this to make 'days remaining' the x-axis\n",
    "                days_df = all_df\n",
    "                days_df['days remaining'] = sorted(range(len(days_df)), reverse=True)\n",
    "                days_df['days remaining'] = days_df['days remaining'].astype('str') \n",
    "                days_df['days remaining'].iloc[-1] = 'After Earnings'\n",
    "                days_df.set_index('days remaining', inplace=True)\n",
    "                # days_df.drop('date', axis=1, inplace=True)\n",
    "                days_df = days_df.transpose()\n",
    "    #             days_df.dropna(how='all', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "                # creates the heatmap\n",
    "                fig = px.imshow(days_df.round(1), color_continuous_scale=[(0,'red'), (0.5,'white'), (1.0, 'green')], range_color=(-100 ,100), text_auto=True)\n",
    "                fig.update_layout(\n",
    "                    title=f'{ticker} ATM Straddle Performance in percent (expires {days_after_earnings} days after earnings) for {earnings_date}',\n",
    "                    title_x=0.5,\n",
    "                    yaxis_title='Straddle Initiated',\n",
    "                    xaxis_title='Trading Days Remaining'\n",
    "                )\n",
    "                fig.update_xaxes(rangebreaks=[dict(bounds=[\"sat\", \"mon\"])]),  # hide weekends, eg. hide sat to before mon])\n",
    "                fig.update(data=[{'customdata': np.dstack((days_df.round(1), date_df)),\n",
    "                    'hovertemplate': '<b>return: %{z:.1f}</b> <br>date: %{customdata[1]}'}])\n",
    "                print(ticker + ' ' + str(earnings_date) + ' complete')\n",
    "\n",
    "                # define dictionary for export pickling\n",
    "                a_dict = {'days_df': days_df, 'date_df': date_df, 'days after earnings': days_after_earnings}\n",
    "\n",
    "                if i == 0:\n",
    "                    near_aggregate_df.append(days_df) # append days_df for aggregate\n",
    "                    near_avg_days_after_earnings.append(days_after_earnings)\n",
    "                    with open(f'data/{ticker}-{earnings_date}-near.pickle', 'wb') as f:\n",
    "                        pickle.dump(a_dict, f)\n",
    "\n",
    "                elif i == 1:\n",
    "                    med_aggregate_df.append(days_df) # append days_df for aggregate\n",
    "                    med_avg_days_after_earnings.append(days_after_earnings)\n",
    "                    with open(f'data/{ticker}-{earnings_date}-med.pickle', 'wb') as f:\n",
    "                        pickle.dump(a_dict, f)\n",
    "                else:\n",
    "                    far_aggregate_df.append(days_df) # append days_df for aggregate\n",
    "                    far_avg_days_after_earnings.append(days_after_earnings)\n",
    "                    with open(f'data/{ticker}-{earnings_date}-far.pickle', 'wb') as f:\n",
    "                        pickle.dump(a_dict, f)\n",
    "            except polygon.exceptions.NoResultsError:\n",
    "                print(f'There was a \"no results\" error! ticker: {ticker}, earnings date: {earnings_date}')\n",
    "                errors.append(f'There was a \"no results\" error! ticker: {ticker}, earnings date: {earnings_date}')\n",
    "            i += 1\n",
    "\n",
    "\n",
    "    near_avg_days_after_earnings = np.mean(near_avg_days_after_earnings)\n",
    "    med_avg_days_after_earnings = np.mean(med_avg_days_after_earnings)\n",
    "    far_avg_days_after_earnings = np.mean(far_avg_days_after_earnings)            \n",
    "\n",
    "    # process the aggregate dfs and put them into a dictionary of dfs\n",
    "    near_dict = process_df(near_aggregate_df, near_avg_days_after_earnings)\n",
    "    med_dict = process_df(med_aggregate_df, med_avg_days_after_earnings)\n",
    "    far_dict = process_df(far_aggregate_df, far_avg_days_after_earnings)\n",
    "\n",
    "    # save agg dictionary of dfs\n",
    "    with open(f'data/{ticker}-agg-near.pickle', 'wb') as f:\n",
    "        pickle.dump(near_dict, f)\n",
    "    with open(f'data/{ticker}-agg-med.pickle', 'wb') as f:\n",
    "        pickle.dump(med_dict, f)\n",
    "    with open(f'data/{ticker}-agg-far.pickle', 'wb') as f:\n",
    "        pickle.dump(far_dict, f)\n",
    "\n",
    "    # iterate over dictionaris for visualization\n",
    "    list_of_aggregates = [near_dict, med_dict, far_dict]\n",
    "\n",
    "    for agg in list_of_aggregates:\n",
    "        avg_days = agg['avg_days']\n",
    "        fig = px.imshow(agg['mean'].round(1), color_continuous_scale=[(0,'red'), (0.5,'white'), (1.0, 'green')], range_color=(-100 ,100), text_auto=True)\n",
    "        fig.update_layout(\n",
    "            title=f'{ticker} ATM Straddle Performance in percent<br>expires ~{avg_days} days after earnings',\n",
    "            title_x=0.5,\n",
    "            yaxis_title='Straddle Initiated',\n",
    "            xaxis_title='Trading Days Remaining'\n",
    "        )\n",
    "        fig.update_xaxes(rangebreaks=[dict(bounds=[\"sat\", \"mon\"])]),  # hide weekends, eg. hide sat to before mon])\n",
    "        fig.update_yaxes(autorange='reversed')\n",
    "\n",
    "        fig.update(data=[{'customdata': np.dstack((agg['median'], agg['max'], agg['min'])),\n",
    "            'hovertemplate': '<b>mean:%{z:.1f}</b> <br>median: %{customdata[0]:.1f} <br>max: %{customdata[1]:.1f} <br>min: %{customdata[2]:.1f}'}])\n",
    "        time.sleep(1)\n",
    "    # export errors\n",
    "    with open(f'data/{ticker}-errors.pickle', 'wb') as f:\n",
    "        pickle.dump(errors, f)\n",
    "    print(f'--------{ticker} is complete----------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:options-backtester]",
   "language": "python",
   "name": "conda-env-options-backtester-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
